{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(reticulate) \n",
    "sagemaker <- import('sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session <- sagemaker$Session() \n",
    "\n",
    "bucket <- session$default_bucket()\n",
    "#creates a default bucket of format sagemaker-<aws-region-name>-<aws account number>\n",
    "\n",
    "role_arn <- sagemaker$get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load my train and test data\n",
    "#The training and test data for this was provided at the following location: http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har\n",
    "train_url <- \"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv\"\n",
    "test_url  <- \"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv\"\n",
    "rawTrainData <- read.csv(url(train_url))\n",
    "rawTestData <- read.csv(url(test_url))\n",
    "dim(rawTrainData)\n",
    "dim(rawTestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(rawTrainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(readr)\n",
    "write_csv(rawTrainData, 'pml-training.csv', col_names = FALSE) \n",
    "write_csv(rawTestData, 'pml-testing.csv', col_names = FALSE)\n",
    "session$upload_data(path = 'pml-training.csv', \n",
    "                                bucket = bucket, \n",
    "                                key_prefix = 'data')\n",
    "session$upload_data(path = 'pml-testing.csv', \n",
    "                                bucket = bucket, \n",
    "                                key_prefix = 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA CLEANSING\n",
    "library(caret)\n",
    "## - check Variance of columns\n",
    "apply(rawTrainData, 2, var)\n",
    "##remove columns with near zero variance\n",
    "nearZeroVarCols <- nearZeroVar(rawTrainData)\n",
    "training <- rawTrainData[,-nearZeroVarCols]\n",
    "testing <- rawTestData[,-nearZeroVarCols]\n",
    "dim(training)\n",
    "dim(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - remove data with NA\n",
    "training <- training[, colSums(is.na(training)) == 0] \n",
    "testing <- testing[, colSums(is.na(testing)) == 0] \n",
    "dim(training)\n",
    "dim(testing)\n",
    "head(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 - remove first 5 columns - user_name, raw_timestamp_part_1, raw_timestamp_part_2,cvtd_timestamp\n",
    "training <-training[,-c(1:5)]\n",
    "testing <- testing[,-c(1:5)]\n",
    "dim(training)\n",
    "dim(testing)\n",
    "head(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We're predicting classe. Move to the first column (since Sagemaker requires it) and change from A,B,C,D,E to 0,1,2,3,4\n",
    "library(tidyverse)\n",
    "training1 <- training %>% relocate(classe)\n",
    "\n",
    "\n",
    "head(training)\n",
    "head(training1)\n",
    "\n",
    "\n",
    "training1$classe<-recode(training1$classe, 'A'=0, 'B'=1, 'C'=2, 'D'=3, 'E'=4)\n",
    "training1$classe  <- as.factor(training1$classe)\n",
    "head(training1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Training and Validation sets\n",
    "subSamples <- createDataPartition(y=training1$classe, p=0.70, list=FALSE)\n",
    "subTraining <- training1[subSamples, ] \n",
    "subValidation <- training1[-subSamples, ]## Going to keep this set aside. Will not be used to build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary(subTraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv(subTraining, 'col_headers.csv', col_names = TRUE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(subTraining)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#will only use the subTraning to train the model\n",
    "subSamples1 <- createDataPartition(y=subTraining$classe, p=0.70, list=FALSE)\n",
    "modTraining <- subTraining[subSamples1, ] \n",
    "modValidation <- subTraining[-subSamples1, ]\n",
    "\n",
    "dim(modTraining)\n",
    "dim(modValidation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv(modTraining, 'clean_train1.csv', col_names = FALSE) \n",
    "write_csv(modValidation, 'clean_valid1.csv', col_names = FALSE)\n",
    "\n",
    "s3_train <- session$upload_data(path = 'clean_train1.csv', \n",
    "                                bucket = bucket, \n",
    "                                key_prefix = 'data')\n",
    "s3_valid <- session$upload_data(path = 'clean_valid1.csv', \n",
    "                                bucket = bucket, \n",
    "                                key_prefix = 'data')\n",
    "\n",
    "s3_train_input <- sagemaker$inputs$TrainingInput(s3_data = s3_train, content_type = 'csv') \n",
    "s3_valid_input <- sagemaker$inputs$TrainingInput(s3_data = s3_valid, content_type = 'csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TRAIN AND DEPLOY A MODEL USING XGBoost. XGBoost is available as one of the core Sagemaker Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RETRIEVE THE LATEST XGBOOST Container Regisry\n",
    "#Note: Getting a specific Repo version since minor differences between versions can break code\n",
    "\n",
    "xgboost_container <- sagemaker$amazon$amazon_estimator$get_image_uri(session$boto_session$region_name,\n",
    "                          'xgboost', \n",
    "                         repo_version='1.2-1')\n",
    "#xgboost_container <- sagemaker$amazon$amazon_estimator$get_image_uri(session$boto_session$region_name,\n",
    "#                          'xgboost', \n",
    "#                         repo_version='latest')\n",
    "\n",
    "xgboost_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output <- paste0('s3://', bucket, '/output')\n",
    "estimator <- sagemaker$estimator$Estimator(image_uri = xgboost_container,\n",
    "                                     role = role_arn,\n",
    "                                     train_instance_count = 1L,\n",
    "                                     train_instance_type = 'ml.m5.large',\n",
    "                                     train_volume_size = 30L,\n",
    "                                     train_max_run = 3600L,\n",
    "                                     input_mode = 'File',\n",
    "                                     output_path = s3_output,\n",
    "                                     output_kms_key = NULL,\n",
    "                                     base_job_name = NULL,\n",
    "                                     sagemaker_session = NULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the hyperparameters. Refer the model parameters trained via the caret package.\n",
    "#an implicit assumption is that the Sagemaker XGBoost is similar to Caret's XGBoost\n",
    "# one difference seems to be that the Sagemaker algorithm does not support k-fold cross validation \n",
    "#(I had done 5-fold in my caret package)\n",
    "estimator$set_hyperparameters(\n",
    "        max_depth = 6L,\n",
    "        eta = 0.05,\n",
    "        gamma = 0.01,\n",
    "        min_child_weight = 0.5,\n",
    "        subsample = 0.5,\n",
    "        objective = \"multi:softmax\", ##since this is a multiclass\n",
    "        num_class = 5L, ## required for multi:softmax\n",
    "        num_round = 100L,\n",
    "        colsample_bytree = 1L )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "estimator$hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIT THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name <- paste('sagemaker-train-xgboost', format(Sys.time(), '%H-%M-%S'), sep = '-')\n",
    "\n",
    "input_data <- list('train' = s3_train_input,\n",
    "                   'validation' = s3_valid_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator$fit(inputs = input_data,\n",
    "              job_name = job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator$model_data\n",
    "estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEPLOY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serializer <- sagemaker$serializers$CSVSerializer(content_type='text/csv')\n",
    "model_endpoint <- estimator$deploy(initial_instance_count = 1L,\n",
    "                                   instance_type = 'ml.t2.medium',serializer=serializer)\n",
    "#model_endpoint <- estimator$deploy(initial_instance_count=1, content_type='text/csv', instance_type='ml.t2.medium'  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(testing)\n",
    "head(testing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv(testing, 'test_data.csv', col_names = FALSE)\n",
    "\n",
    "s3_test <- session$upload_data(path = 'test_data.csv', \n",
    "                                bucket = bucket, \n",
    "                                key_prefix = 'data')\n",
    "\n",
    "s3_test_input <- sagemaker$inputs$TrainingInput(s3_data = s3_test, content_type = 'csv') \n",
    "\n",
    "s3_test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_endpoint$content_type \n",
    "model_endpoint$serializer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing1 <- testing[,-c(54)]\n",
    "head(testing1)\n",
    "test_sample <- as.matrix(testing1[1:20, ])\n",
    "predictions <- model_endpoint$predict(test_sample)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1 <- str_split(predictions, pattern = ',', simplify = TRUE)\n",
    "predictions1 <- as.numeric(predictions1)\n",
    "predictions1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output1 <- cbind(predicted_classe = as.integer(predictions1), testing1[1:20, ])\n",
    "head(output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(subValidation)\n",
    "head(subValidation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val1 <- subValidation[,-c(1)]\n",
    "head(val1)\n",
    "valset <- as.matrix(val1 [1:5885, ])\n",
    "predictions2 <- model_endpoint$predict(valset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 <- str_split(predictions2, pattern = ',', simplify = TRUE)\n",
    "predictions2 <- as.numeric(predictions2)\n",
    "output2 <- cbind(predicted_classe = as.integer(predictions2), subValidation[1:5885, ])\n",
    "head(output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confMat_Val = table(output2$predicted_classe, output2$classe)\n",
    "accuracy_Val <- sum(diag(confMat_Val))/sum(confMat_Val)\n",
    "oose_Val <- 1 - accuracy_Val\n",
    "\n",
    "confMat_Val\n",
    "accuracy_Val\n",
    "oose_Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FINALLY DELETE THE ENDPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session$delete_endpoint(model_endpoint$endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
